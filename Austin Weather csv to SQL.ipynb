{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import CSV into PostgreSQL database\n",
    "The goal of this project is to import a CSV file into a PostgreSQL database.It's important that you already have a PostgreSQL server installed on your machine and have created user access for the database. The steps to be followed are:\n",
    "1. Understand the data from the CSV file\n",
    "2. Create a SQL table that fits the data\n",
    "3. Import a single value to the database\n",
    "4. Import a row to the database\n",
    "5. Import all the rows\n",
    "Let's see which surprises await!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: read csv\n",
    "Firstly, we need to be able to load the data into Python and get a feel for what it looks like. We'll use the csv library in Python to handle the file import. Let's print the column headers and first row of data to get a better feel for what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'TempHighF', 'TempAvgF', 'TempLowF', 'DewPointHighF', 'DewPointAvgF', 'DewPointLowF', 'HumidityHighPercent', 'HumidityAvgPercent', 'HumidityLowPercent', 'SeaLevelPressureHighInches', 'SeaLevelPressureAvgInches', 'SeaLevelPressureLowInches', 'VisibilityHighMiles', 'VisibilityAvgMiles', 'VisibilityLowMiles', 'WindHighMPH', 'WindAvgMPH', 'WindGustMPH', 'PrecipitationSumInches', 'Events']\n",
      "['2013-12-21', '74', '60', '45', '67', '49', '43', '93', '75', '57', '29.86', '29.68', '29.59', '10', '7', '2', '20', '4', '31', '0.46', 'Rain , Thunderstorm']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('austin_weather.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    columns = next(reader)\n",
    "    first_row = next(reader)\n",
    "    second_row = next(reader)\n",
    "    print(columns)\n",
    "    print(first_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first row contains the headers, after that the values follow. With the exception of the first and the last columns, data seems to be numerical. Let's make sure that all the rows within the file contain the same amount of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('austin_weather.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    f.seek(0)\n",
    "    for row in f:\n",
    "        my_row = next(reader)\n",
    "        if not len(my_row) == 21:\n",
    "            print (\"row length not 21!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good news everyone! All rows contain 21 values, so no need to worry about the shape of the file. Next, let's create an SQL table with a column for each value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: create an SQL table which fits the data\n",
    "The statement sql_create_weather_table will create the new table for us. Each column in our .csv file gets its own column in the table. Note that an ID column was added (which is not contained in the orginial data file). This is because the SQL database requires a unique field. We've set the ID to \"serial\" so that it will automatically increase when a new value is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to austin_weather_energy\n",
      "Columns in database:\n",
      "['id', 'date', 'temphighf', 'tempavgf', 'templowf', 'dewpointhighf', 'dewpointavgf', 'dewpointlowf', 'humidityhighpercent', 'humidityavgpercent', 'humiditylowpercent', 'sealevelpressurehighinches', 'sealevelpressureavginches', 'sealevelpressurelowinches', 'visibilityhighmiles', 'visibilityavgmiles', 'visibilitylowmiles', 'windhighmph', 'windavgmph', 'windgustmph', 'precipitationsuminches', 'events']\n",
      "Values in database:\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "sql_create_weather_table = \"\"\"CREATE TABLE IF NOT EXISTS weather(\n",
    "                                ID SERIAL PRIMARY KEY,\n",
    "                                date date,\n",
    "                                TempHighF integer,\n",
    "                                TempAvgF integer,\n",
    "                                TempLowF integer,\n",
    "                                DewPointHighF integer,\n",
    "                                DewPointAvgF integer,\n",
    "                                DewPointLowF integer,\n",
    "                                HumidityHighPercent integer,\n",
    "                                HumidityAvgPercent integer,\n",
    "                                HumidityLowPercent integer,\n",
    "                                SeaLevelPressureHighInches real,\n",
    "                                SeaLevelPressureAvgInches real,\n",
    "                                SeaLevelPressureLowInches real,\n",
    "                                VisibilityHighMiles integer,\n",
    "                                VisibilityAvgMiles integer,\n",
    "                                VisibilityLowMiles integer,\n",
    "                                WindHighMPH integer,\n",
    "                                WindAvgMPH integer,\n",
    "                                WindGustMPH integer,\n",
    "                                PrecipitationSumInches real,\n",
    "                                Events text\n",
    "                                )\"\"\"   \n",
    "\n",
    "# create a connection with the database (this should already exist)\n",
    "try:\n",
    "    connection = psycopg2.connect(\"dbname='austin_weather_energy' user='muriel' host='localhost' password='1'\")\n",
    "    print(\"connected to austin_weather_energy\")\n",
    "except:\n",
    "    print(\"Unable to connect to the database\")\n",
    "# the cursor can help us execute SQL\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# delete the table if it already exists\n",
    "sql = \"\"\"DROP table weather\"\"\"\n",
    "cursor.execute(sql)\n",
    "connection.commit()\n",
    "\n",
    "# now let's create the table\n",
    "cursor.execute(sql_create_weather_table)\n",
    "# and commit to the DB\n",
    "connection.commit()\n",
    "\n",
    "# next, let's print the column names to see if it worked:\n",
    "\n",
    "\n",
    "def print_values():\n",
    "    cursor.execute(\"SELECT * from weather\")\n",
    "    colnames = [desc[0] for desc in cursor.description]\n",
    "    print(\"Columns in database:\")\n",
    "    print(colnames)\n",
    "    rows = cursor.fetchall()\n",
    "    print(\"Values in database:\")\n",
    "    for row in rows[0:4]: #only print first 5 rows to avoid clutter\n",
    "        print(\" \", row)\n",
    "    connection.commit()\n",
    "\n",
    "# print the first 5 values     \n",
    "print_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurrah! We've managed to create a table in our database. At this point in time the table is empty (as shown by the print_values function. Next, let's add some values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Import a single value into the Database\n",
    "I always like breaking complex problems into little pieces, so let's get started by importing only a single value into the database and print that. If that works, we can move on to more complicated stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-12-21\n",
      "Columns in database:\n",
      "['id', 'date', 'temphighf', 'tempavgf', 'templowf', 'dewpointhighf', 'dewpointavgf', 'dewpointlowf', 'humidityhighpercent', 'humidityavgpercent', 'humiditylowpercent', 'sealevelpressurehighinches', 'sealevelpressureavginches', 'sealevelpressurelowinches', 'visibilityhighmiles', 'visibilityavgmiles', 'visibilitylowmiles', 'windhighmph', 'windavgmph', 'windgustmph', 'precipitationsuminches', 'events']\n",
      "Values in database:\n",
      "  (1, datetime.date(2013, 12, 21), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None)\n"
     ]
    }
   ],
   "source": [
    "# now let's try to add a single value to the database\n",
    "print(first_row[0])\n",
    "sql = \"\"\"INSERT INTO weather(date) VALUES (%r)\"\"\" %(first_row[0])\n",
    "cursor.execute(sql)\n",
    "connection.commit()\n",
    "print_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've sucessfully managed to input the first value (which happens to be a date) into the first row. Note the format of the date (datetime.date) which means that Postgres automatically converted the string from the CSV into a datetime. Here we need to be careful, dates can go wront in many different ways - but let's not think about that for the time being.\n",
    "\n",
    "Everything else is still empty (or \"None\" in PostgreSQL terms), but this proves that we are able to write to the database and read & display values. Good progress!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Import a row\n",
    "With data you never know where it's going to go wrong, points might ben decimals or stings can contain characters which break everything. If we try to dump the entire csv to the db, we won't know where things went wrong, so let's try to input each column at least once to ensure there are no conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in database:\n",
      "['id', 'date', 'temphighf', 'tempavgf', 'templowf', 'dewpointhighf', 'dewpointavgf', 'dewpointlowf', 'humidityhighpercent', 'humidityavgpercent', 'humiditylowpercent', 'sealevelpressurehighinches', 'sealevelpressureavginches', 'sealevelpressurelowinches', 'visibilityhighmiles', 'visibilityavgmiles', 'visibilitylowmiles', 'windhighmph', 'windavgmph', 'windgustmph', 'precipitationsuminches', 'events']\n",
      "Values in database:\n",
      "  (1, datetime.date(2013, 12, 21), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None)\n",
      "  (2, datetime.date(2013, 12, 21), None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None)\n",
      "  (3, None, 74, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None)\n",
      "  (4, None, None, 60, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None)\n"
     ]
    }
   ],
   "source": [
    "# next let's try to add the first row's values into the database one by one. This will help us\n",
    "# understand if there are any conflicts between the data types of the csv versus the SQL database\n",
    "\n",
    "for colname, value in zip(columns, first_row):\n",
    "    sql = \"\"\"INSERT INTO weather(%s) VALUES (%r)\"\"\" %(colname,value)\n",
    "    #print(sql)\n",
    "    cursor.execute(sql)\n",
    "    connection.commit()\n",
    "# print the first 5 values    \n",
    "print_values()    \n",
    "# note that each item is inserted in a new row, which is not what we want, but for now it's good\n",
    "# enough as we're only trying to check if the data can be transferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No errors, that's great news! We've also managed to print the first five rows to see that the auto-incriment function works. Each value is in it's own new row at the moment, because the database creates a new row each tie the cursor executes. This is not what we want,so let's clean that up before continuing. Notice the frightening eas with which SQL deletes an entire table, no questions asked... Yikes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the table if it already exists\n",
    "sql = \"\"\"DROP table weather\"\"\"\n",
    "cursor.execute(sql)\n",
    "connection.commit()\n",
    "\n",
    "# now let's create the table\n",
    "cursor.execute(sql_create_weather_table)\n",
    "# and commit to the DB\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Import all the rows\n",
    "When we try to import all the rows, we get SQL errors a bunch of times. Trial and error shows that the data needs to be pre-processed for the following:\n",
    "1. adding quotation marks around the \"Date\" column (otherwise the \"-\" is interpreted as a minus)\n",
    "2. adding quotation marks around the \"Events\" column (some of the values contain commas)\n",
    "3. Replacing \"-\" and \"F\" numerical values with NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('austin_weather.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    columns = next(reader)  \n",
    "    f.seek(0)\n",
    "    for row in f:\n",
    "        my_row = next(reader)\n",
    "        last_value = my_row[len(my_row)-1]\n",
    "        # Add ' around the text in the last column to prevent and SQL error for handling a string with a comma:\n",
    "        last_value = \"'\"+last_value+\"'\"    \n",
    "        my_row[len(my_row)-1] = last_value\n",
    "        my_row[0] = \"'\"+my_row[0]+\"'\"\n",
    "        # Replace non-numerical values with NULL\n",
    "        for j in range(0,len(my_row)):\n",
    "            if my_row[j] == \"T\":\n",
    "                my_row[j] = \"NULL\"\n",
    "            if my_row[j] == \"-\":\n",
    "                my_row[j] = \"NULL\"\n",
    "        sql = \"\"\"INSERT INTO weather({0}) VALUES ({1})\"\"\"\n",
    "        sql = sql.format(','.join(columns), ','.join(my_row))\n",
    "        cursor.execute(sql)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works without errors! Next, let's see the data in our database (we'll only pring the first five rows to avoid cluttering):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in database:\n",
      "['id', 'date', 'temphighf', 'tempavgf', 'templowf', 'dewpointhighf', 'dewpointavgf', 'dewpointlowf', 'humidityhighpercent', 'humidityavgpercent', 'humiditylowpercent', 'sealevelpressurehighinches', 'sealevelpressureavginches', 'sealevelpressurelowinches', 'visibilityhighmiles', 'visibilityavgmiles', 'visibilitylowmiles', 'windhighmph', 'windavgmph', 'windgustmph', 'precipitationsuminches', 'events']\n",
      "Values in database:\n",
      "  (1, datetime.date(2013, 12, 21), 74, 60, 45, 67, 49, 43, 93, 75, 57, 29.86, 29.68, 29.59, 10, 7, 2, 20, 4, 31, 0.46, 'Rain , Thunderstorm')\n",
      "  (2, datetime.date(2013, 12, 23), 58, 45, 32, 31, 27, 23, 76, 52, 27, 30.56, 30.49, 30.41, 10, 10, 10, 8, 3, 12, 0.0, ' ')\n",
      "  (3, datetime.date(2013, 12, 25), 58, 50, 41, 44, 40, 36, 86, 71, 56, 30.41, 30.33, 30.27, 10, 10, 7, 10, 2, 16, None, ' ')\n",
      "  (4, datetime.date(2013, 12, 27), 60, 53, 45, 41, 39, 37, 83, 65, 47, 30.46, 30.39, 30.34, 10, 9, 7, 7, 1, 11, None, ' ')\n"
     ]
    }
   ],
   "source": [
    "print_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and finally let's close the connection and the cursor:\n",
    "connection.close()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "It's possible to import a .csv file into a PostGreSQL database using the psycopg2 and csv libraries in Python. It's a good idea to first understand the data in the csv and start small, first importing only one value, then values one at a time and finally one row at a time. A very important part of the process is checking the data every step of the way and making sure what you thought would happen actually happened."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
